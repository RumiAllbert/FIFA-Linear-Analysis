---
title: "R Notebook"
output: html_notebook
---

```{r, echo=FALSE, results=FALSE, include=FALSE}
knitr::opts_chunk$set(fig.width=4.5, fig.height=4)
library(ggplot2)
library(tidyverse)
library(olsrr)
library(caret)
library(texreg)
library(leaps)
```


```{r, echo=FALSE, results=FALSE}
df=read.csv("/Users/rumiallbert/Library/CloudStorage/GoogleDrive-rumiallbert@gmail.com/My Drive/Fei Tian Middletown /Fall 2022/Applied Regression Analysis/Final Project/data/model_df.csv")
#df$wage = df$wage*52
head(df)
```

# Full Model

```{r}
fm_model = lm(value~., data=df)
summary(fm_model)
plot(fm_model)
```
# Reduced Model

##Transform Label

Transform the label using Box Cox

```{r}
model_df = df

BCM <- BoxCoxTrans(df$value)
model_df$value <- predict(BCM, df$value)

head(model_df)
```
```{r}
hist(df$value, breaks=100, main='Histogram of Value label', xlab='Value')
```


```{r}
hist(model_df$value, breaks=100, main='Histogram of Value label', xlab='Value')
```

## Stepwise Regression

Using stepwise regression, let's get the best reduced model given the AIC as the standard of measure.

```{r}
row.number <- sample(1:nrow(model_df), 0.8*nrow(model_df))
df_clean = model_df[row.number,]
test = model_df[-row.number,]

model = lm(value ~ . , data=df_clean)
```


```{r}
step = ols_step_both_aic(model)
```
```{r}
step$model
```

## Fit the reduced model and eliminate outliers that are three standard deviations away


```{r}
# df_clean = model_df[sample(nrow(model_df), 1000), ]
row.number <- sample(1:nrow(model_df), 0.8*nrow(model_df))
df_clean = model_df[row.number,]
test = model_df[-row.number,]
for (x in 0:4) {
  print(nrow(df_clean))

  # model = lm(log(value) ~  wage+ potential + real_face + movement_balance + mentality_penalties + club_team_id + mentality_aggression+ attacking_crossing  + international_reputation + pace + league_level + power_stamina + overall + physic + power_jumping + skill_long_passing + age + nation_jersey_number + attacking_volleys + player_positions_FWD, data=df_clean)

  
  model = lm(value ~ age + physic + wage + potential +  overall  + international_reputation , data=df_clean)
  stud = ols_plot_dffits(model, print_plot=F)
  df_clean = df_clean[-c(stud$outliers$observation), ]
  
}
summary(model)
plot(model, 1)
plot(model, 2)
# ols_plot_dffits(model)
ols_plot_cooksd_bar(model)
ols_plot_resid_stud(model)
```
## Testing on New Data


```{r}
pred1 <- predict(model, newdata=test)

rmse <- sqrt(sum((exp(pred1) - test$value)^2)/length(test$value))
c(RMSE = rmse, R2=summary(model)$r.squared)

par(mfrow=c(1,1))
plot(test$value, exp(pred1))
```

$\widehat{value}^{-.1}=350.8-0.06652age-0.001394physic+0.000003400wage+0.0251potential+1.536overall+0.2505reputation$

```{r}
library("PerformanceAnalytics")
myvars <- c('value', 'age' , 'physic' , 'mentality_aggression' , 'potential' , 'release_clause' , 'wage' , 'club_team_id' , 'movement_balance' , 'potential')
check = model_df[myvars]
check = check[sample(nrow(check), 5000), ]
chart.Correlation(check, histogram=TRUE, pch=25)

```

